# YouTube AI åŠ©æ‰‹æŠ€è¡“å¯¦ç¾è©³ç´°èªªæ˜

æœ¬æ–‡æª”è©³ç´°ä»‹ç´¹å„å€‹ç³»çµ±æ¨¡å¡Šçš„æŠ€è¡“å¯¦ç¾æ–¹æ³•ï¼ŒåŒ…æ‹¬æ‰€ç”¨å·¥å…·ã€ä»£ç¢¼çµ„ç¹”ã€é—œéµç®—æ³•å’Œæ•´åˆæ–¹å¼ã€‚

## ç’°å¢ƒé…ç½®

### ä¾è³´é …ç®¡ç†

```python
# requirements.txt
streamlit==1.43.1
langgraph==0.3.21
langchain==0.2.10
langchain-openai==0.0.5
langchain-community==0.0.13
youtube-transcript-api==0.6.1
faiss-cpu==1.7.4
python-dotenv==1.0.0
pytube==15.0.0
requests==2.31.0
pydantic==2.7.1
```

### é…ç½®æ–‡ä»¶

æˆ‘å€‘ä½¿ç”¨ `.env` æ–‡ä»¶ä¾†å­˜å„²æ•æ„Ÿä¿¡æ¯ï¼Œå¦‚ API å¯†é‘°ï¼š

```
# .env
OPENAI_API_KEY=your_openai_api_key
# å¯é¸çš„å…¶ä»– LLM API å¯†é‘°
ANTHROPIC_API_KEY=your_anthropic_api_key
```

## 1. YouTube å­—å¹•æå–æ¨¡å¡Š

### æ ¸å¿ƒåŠŸèƒ½å¯¦ç¾

```python
from youtube_transcript_api import YouTubeTranscriptApi
from pytube import YouTube
import re

def extract_video_id(youtube_url: str) -> str:
    """å¾ YouTube URL ä¸­æå–è¦–é » ID"""
    # æ”¯æŒå¤šç¨® YouTube URL æ ¼å¼
    patterns = [
        r'(?:https?:\/\/)?(?:www\.)?youtube\.com\/watch\?v=([^&\s]+)',
        r'(?:https?:\/\/)?(?:www\.)?youtu\.be\/([^\?\s]+)',
        r'(?:https?:\/\/)?(?:www\.)?youtube\.com\/embed\/([^\?\s]+)'
    ]

    for pattern in patterns:
        match = re.search(pattern, youtube_url)
        if match:
            return match.group(1)

    raise ValueError("ç„¡æ³•å¾æä¾›çš„ URL ä¸­æå–è¦–é » ID")

def get_video_info(video_id: str) -> dict:
    """ç²å–è¦–é »çš„åŸºæœ¬ä¿¡æ¯"""
    try:
        yt = YouTube(f"https://www.youtube.com/watch?v={video_id}")
        return {
            "title": yt.title,
            "author": yt.author,
            "length": yt.length,
            "publish_date": yt.publish_date,
            "thumbnail_url": yt.thumbnail_url,
            "views": yt.views
        }
    except Exception as e:
        raise Exception(f"ç²å–è¦–é »ä¿¡æ¯æ™‚å‡ºéŒ¯: {str(e)}")

def get_video_transcript(video_id: str, language: str = "en") -> list:
    """ç²å–è¦–é »å­—å¹•"""
    try:
        transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)

        # å˜—è©¦ç²å–æŒ‡å®šèªè¨€çš„å­—å¹•
        try:
            transcript = transcript_list.find_transcript([language])
        except:
            # å¦‚æœå¤±æ•—ï¼Œå˜—è©¦ç²å–å¯ç”¨çš„å­—å¹•ä¸¦ç¿»è­¯
            transcript = transcript_list.find_transcript(['en'])
            if language != 'en':
                transcript = transcript.translate(language)

        return transcript.fetch()
    except Exception as e:
        raise Exception(f"ç²å–è¦–é »å­—å¹•æ™‚å‡ºéŒ¯: {str(e)}")

def format_transcript(transcript: list) -> dict:
    """æ ¼å¼åŒ–å­—å¹•æ•¸æ“š"""
    formatted_text = ""
    segments = []

    for segment in transcript:
        text = segment['text']
        start = segment['start']
        duration = segment['duration']

        # æ ¼å¼åŒ–æ™‚é–“æˆ³
        start_time = format_timestamp(start)
        end_time = format_timestamp(start + duration)

        # æ·»åŠ åˆ°å®Œæ•´æ–‡æœ¬
        formatted_text += f"{text} "

        # ä¿å­˜åˆ†æ®µä¿¡æ¯
        segments.append({
            "text": text,
            "start": start,
            "start_formatted": start_time,
            "end": start + duration,
            "end_formatted": end_time
        })

    return {
        "full_text": formatted_text.strip(),
        "segments": segments
    }

def format_timestamp(seconds: float) -> str:
    """å°‡ç§’æ•¸è½‰æ›ç‚ºæ™‚:åˆ†:ç§’æ ¼å¼"""
    minutes, seconds = divmod(int(seconds), 60)
    hours, minutes = divmod(minutes, 60)

    if hours > 0:
        return f"{hours:02d}:{minutes:02d}:{seconds:02d}"
    else:
        return f"{minutes:02d}:{seconds:02d}"
```

## 2. å…§å®¹è™•ç†æ¨¡å¡Š

### æ–‡æœ¬åˆ†å‰²å’Œå‘é‡åŒ–

```python
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import FAISS
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.docstore.document import Document

def split_and_vectorize_transcript(transcript_text: str, video_id: str, chunk_size: int = 1000, chunk_overlap: int = 100) -> FAISS:
    """å°‡å­—å¹•æ–‡æœ¬åˆ†å‰²ä¸¦å‘é‡åŒ–"""
    # å‰µå»ºæ–‡æœ¬åˆ†å‰²å™¨
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_size,
        chunk_overlap=chunk_overlap
    )

    # å°‡æ–‡æœ¬åˆ†å‰²æˆæ–‡æª”
    docs = text_splitter.create_documents([transcript_text])

    # ç‚ºæ¯å€‹æ–‡æª”æ·»åŠ å…ƒæ•¸æ“š
    for doc in docs:
        doc.metadata = {"source": f"youtube_video_{video_id}"}

    # å‰µå»ºåµŒå…¥æ¨¡å‹
    embeddings = OpenAIEmbeddings()

    # å‰µå»ºå‘é‡å­˜å„²
    vector_store = FAISS.from_documents(docs, embeddings)

    return vector_store
```

## 3. ç¿»è­¯æ¨¡å¡Š

### ä½¿ç”¨ LLM é€²è¡Œç¿»è­¯

```python
from langchain.llms import OpenAI
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate

def translate_segments(segments: list, target_language: str = "ä¸­æ–‡") -> list:
    """ç¿»è­¯å­—å¹•åˆ†æ®µ"""
    # å‰µå»º LLM
    llm = OpenAI(temperature=0.1)

    # å‰µå»ºç¿»è­¯æç¤ºæ¨¡æ¿
    prompt_template = PromptTemplate(
        input_variables=["text"],
        template=f"å°‡ä»¥ä¸‹æ–‡æœ¬æº–ç¢ºåœ°ç¿»è­¯æˆ{target_language}ï¼Œä¿æŒåŸæ„ã€‚æ–‡æœ¬ï¼š{{text}}"
    )

    # å‰µå»ºç¿»è­¯éˆ
    translate_chain = LLMChain(llm=llm, prompt=prompt_template)

    # ç¿»è­¯æ¯å€‹åˆ†æ®µ
    translated_segments = []
    for segment in segments:
        translation = translate_chain.run(segment["text"]).strip()

        translated_segment = segment.copy()
        translated_segment["translation"] = translation
        translated_segments.append(translated_segment)

    return translated_segments
```

## 4. å…§å®¹ç¸½çµæ¨¡å¡Š

### ä½¿ç”¨ LangGraph ç”Ÿæˆæ‘˜è¦

```python
from langgraph.graph import StateGraph, END
from langchain.prompts.chat import ChatPromptTemplate
from langchain.schema.runnable import RunnablePassthrough
from langchain.chat_models import ChatOpenAI
from typing import TypedDict, List, Optional
from langchain.schema import Document

# å®šç¾©ç‹€æ…‹é¡å‹
class SummaryState(TypedDict):
    documents: List[Document]
    query: str
    summary: Optional[str]

# ç²å–è¦–é »æ‘˜è¦ç¯€é»
def get_summary(state: SummaryState) -> SummaryState:
    """åŸºæ–¼æ–‡æª”ç”Ÿæˆè¦–é »æ‘˜è¦"""
    # çµ„åˆæ‰€æœ‰æ–‡æª”çš„å…§å®¹
    text_content = "\n\n".join([doc.page_content for doc in state["documents"]])

    # å‰µå»ºæ‘˜è¦æç¤º
    prompt = ChatPromptTemplate.from_template(
        """ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„è¦–é »å…§å®¹åˆ†æå¸«ã€‚æ ¹æ“šä»¥ä¸‹è¦–é »å­—å¹•å…§å®¹ï¼Œç”Ÿæˆä¸€å€‹å…¨é¢çš„æ‘˜è¦ã€‚
        æ‘˜è¦æ‡‰è©²åŒ…æ‹¬ï¼š
        1. è¦–é »çš„ä¸»è¦ä¸»é¡Œå’Œç›®çš„
        2. é—œéµé»å’Œä¸»è¦è«–é»
        3. é‡è¦çš„ç´°ç¯€å’Œä¾‹å­
        4. è¦–é »çš„æ•´é«”çµæ§‹å’Œæµç¨‹

        è¦–é »å­—å¹•å…§å®¹:
        {text}

        è«‹æä¾›ä¸€å€‹çµæ§‹åŒ–çš„æ‘˜è¦ï¼Œä½¿ç”¨æ¨™é¡Œå’Œå­æ¨™é¡Œçµ„ç¹”å…§å®¹ã€‚"""
    )

    # å‰µå»ºæ¨¡å‹å’Œéˆ
    model = ChatOpenAI(temperature=0)
    chain = prompt | model

    # ç”Ÿæˆæ‘˜è¦
    summary = chain.invoke({"text": text_content})

    # æ›´æ–°ç‹€æ…‹
    state["summary"] = summary.content
    return state

# å‰µå»ºæ‘˜è¦å·¥ä½œæµåœ–
def create_summary_graph():
    """å‰µå»ºæ‘˜è¦ç”Ÿæˆå·¥ä½œæµåœ–"""
    # åˆå§‹åŒ–åœ–
    workflow = StateGraph(SummaryState)

    # æ·»åŠ ç¯€é»
    workflow.add_node("get_summary", get_summary)

    # è¨­ç½®é‚Š
    workflow.set_entry_point("get_summary")
    workflow.add_edge("get_summary", END)

    # ç·¨è­¯åœ–
    return workflow.compile()

def generate_video_summary(vector_store, query: str = "ç¸½çµé€™å€‹è¦–é »çš„å…§å®¹") -> str:
    """ç”Ÿæˆè¦–é »æ‘˜è¦"""
    # ç²å–ç›¸é—œæ–‡æª”
    docs = vector_store.similarity_search(query, k=10)

    # å‰µå»ºåˆå§‹ç‹€æ…‹
    initial_state = {
        "documents": docs,
        "query": query,
        "summary": None
    }

    # åŸ·è¡Œæ‘˜è¦åœ–
    summary_graph = create_summary_graph()
    result = summary_graph.invoke(initial_state)

    return result["summary"]
```

## 5. å°è©±åŠ©æ‰‹æ¨¡å¡Š

### ä½¿ç”¨ LangGraph æ§‹å»ºå°è©±ä»£ç†

```python
from typing import List, Dict, TypedDict, Optional, Annotated, Union
from langchain.schema.messages import (
    AIMessage, HumanMessage, SystemMessage, FunctionMessage
)
from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode, tools_condition
from langchain.tools import BaseTool, StructuredTool, tool
from langchain.chat_models import ChatOpenAI
from langgraph.checkpoint.memory import MemorySaver

# å®šç¾©å°è©±ç‹€æ…‹
class ChatState(TypedDict):
    messages: Annotated[List[Union[AIMessage, HumanMessage, SystemMessage, FunctionMessage]], add_messages]
    video_id: str

# å‰µå»ºæœç´¢å·¥å…·
@tool
def search_video_content(query: str, vector_store) -> str:
    """å¾è¦–é »å…§å®¹ä¸­æœç´¢ç›¸é—œä¿¡æ¯"""
    docs = vector_store.similarity_search(query, k=3)
    if not docs:
        return "æ‰¾ä¸åˆ°ç›¸é—œä¿¡æ¯ã€‚"

    content = "\n\n".join([doc.page_content for doc in docs])
    return content

# æ§‹å»º LLM ä»£ç†
def create_chat_agent(video_info: dict, vector_store):
    """å‰µå»ºåŸºæ–¼è¦–é »å…§å®¹çš„å°è©±ä»£ç†"""
    # å‰µå»ºç³»çµ±æç¤º
    system_prompt = f"""ä½ æ˜¯ä¸€å€‹å‹å¥½ã€å°ˆæ¥­çš„ AI åŠ©æ‰‹ï¼Œå°ˆé–€è§£ç­”é—œæ–¼ä»¥ä¸‹è¦–é »çš„å•é¡Œï¼š
    æ¨™é¡Œ: {video_info['title']}
    ä½œè€…: {video_info['author']}

    ä½ å¯ä»¥ä½¿ç”¨æœç´¢å·¥å…·æŸ¥æ‰¾è¦–é »ä¸­çš„ç›¸é—œå…§å®¹ä¾†å›ç­”å•é¡Œã€‚
    å¦‚æœç”¨æˆ¶å•çš„å•é¡Œèˆ‡è¦–é »ç„¡é—œï¼Œè«‹ç¦®è²Œåœ°æé†’ä»–å€‘ä½ çš„å°ˆé•·æ˜¯è¨è«–é€™å€‹ç‰¹å®šè¦–é »çš„å…§å®¹ã€‚
    ç¸½æ˜¯æä¾›æº–ç¢ºã€æœ‰å¹«åŠ©ã€ç›¸é—œçš„ä¿¡æ¯ï¼Œä¸¦å¼•ç”¨è¦–é »ä¸­çš„å…·é«”å…§å®¹ã€‚
    """

    # å‰µå»ºæ¨¡å‹
    model = ChatOpenAI(temperature=0.7)

    # å‰µå»ºæœç´¢å·¥å…·
    search_tool = StructuredTool.from_function(
        func=lambda query: search_video_content(query, vector_store),
        name="search_video_content",
        description="å¾è¦–é »å…§å®¹ä¸­æœç´¢ç›¸é—œä¿¡æ¯"
    )

    # å®šç¾©ä»£ç†ç¯€é»
    def agent_node(state):
        """LLM ä»£ç†ç¯€é»"""
        messages = state["messages"]

        # å¦‚æœæ˜¯ç¬¬ä¸€æ¢æ¶ˆæ¯ï¼Œæ·»åŠ ç³»çµ±æç¤º
        if len(messages) == 1 and isinstance(messages[0], HumanMessage):
            messages = [SystemMessage(content=system_prompt)] + messages

        # èª¿ç”¨æ¨¡å‹
        response = model.invoke(messages)
        return {"messages": [response]}

    # å®šç¾©å·¥å…·ç¯€é»
    tools_node = ToolNode([search_tool])

    # å‰µå»ºåœ–
    workflow = StateGraph(ChatState)

    # æ·»åŠ ç¯€é»
    workflow.add_node("agent", agent_node)
    workflow.add_node("tools", tools_node)

    # æ·»åŠ é‚Š
    workflow.set_entry_point("agent")
    workflow.add_conditional_edges(
        "agent",
        tools_condition,
        {
            "tools": "tools",
            END: END
        }
    )
    workflow.add_edge("tools", "agent")

    # æ·»åŠ è¨˜æ†¶é«”æ”¯æŒ
    memory = MemorySaver()

    # ç·¨è­¯åœ–
    return workflow.compile(checkpointer=memory)

# ä½¿ç”¨ä»£ç†é€²è¡Œå°è©±
def chat_with_video(chat_agent, query: str, thread_id: str, video_id: str):
    """èˆ‡è¦–é »å…§å®¹å°è©±"""
    # è¨­ç½®é…ç½®
    config = {"configurable": {"thread_id": thread_id}}

    # å‰µå»ºæ¶ˆæ¯
    messages = [HumanMessage(content=query)]

    # åˆå§‹ç‹€æ…‹
    state = {
        "messages": messages,
        "video_id": video_id
    }

    # èª¿ç”¨ä»£ç†
    result = chat_agent.invoke(state, config=config)

    # è¿”å›çµæœ
    return result["messages"][-1].content
```

## 6. Streamlit å‰ç«¯ç•Œé¢

### ä¸»ç•Œé¢å¯¦ç¾

```python
import streamlit as st
import json
import time

def main():
    """ä¸»å‡½æ•¸"""
    # è¨­ç½®é é¢é…ç½®
    st.set_page_config(
        page_title="YouTube AI åŠ©æ‰‹",
        page_icon="ğŸ¬",
        layout="wide"
    )

    # æ¨™é¡Œ
    st.title("YouTube AI åŠ©æ‰‹")
    st.subheader("è§£æã€ç¿»è­¯å’Œäº’å‹•æ¢ç´¢ YouTube è¦–é »å…§å®¹")

    # åˆå§‹åŒ–æœƒè©±ç‹€æ…‹
    if "video_processed" not in st.session_state:
        st.session_state.video_processed = False
    if "video_id" not in st.session_state:
        st.session_state.video_id = ""
    if "vector_store" not in st.session_state:
        st.session_state.vector_store = None
    if "chat_agent" not in st.session_state:
        st.session_state.chat_agent = None
    if "thread_id" not in st.session_state:
        st.session_state.thread_id = str(int(time.time()))
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []

    # å´é‚Šæ¬„ - è¦–é »è¼¸å…¥
    with st.sidebar:
        st.header("è¼¸å…¥ YouTube è¦–é »")
        youtube_url = st.text_input("è¼¸å…¥ YouTube è¦–é » URL")
        process_button = st.button("è™•ç†è¦–é »")

        # å¦‚æœç”¨æˆ¶é»æ“Šè™•ç†æŒ‰éˆ•
        if process_button and youtube_url:
            try:
                with st.spinner("è™•ç†è¦–é »ä¸­..."):
                    # æå–è¦–é » ID
                    video_id = extract_video_id(youtube_url)
                    st.session_state.video_id = video_id

                    # ç²å–è¦–é »ä¿¡æ¯
                    video_info = get_video_info(video_id)
                    st.session_state.video_info = video_info

                    # ç²å–è¦–é »å­—å¹•
                    transcript = get_video_transcript(video_id)
                    formatted_transcript = format_transcript(transcript)
                    st.session_state.transcript = formatted_transcript

                    # è™•ç†å­—å¹•ä¸¦å‘é‡åŒ–
                    vector_store = split_and_vectorize_transcript(
                        formatted_transcript["full_text"],
                        video_id
                    )
                    st.session_state.vector_store = vector_store

                    # ç¿»è­¯å­—å¹•
                    translated_segments = translate_segments(formatted_transcript["segments"])
                    st.session_state.translated_segments = translated_segments

                    # ç”Ÿæˆè¦–é »æ‘˜è¦
                    summary = generate_video_summary(vector_store)
                    st.session_state.summary = summary

                    # å‰µå»ºèŠå¤©ä»£ç†
                    chat_agent = create_chat_agent(video_info, vector_store)
                    st.session_state.chat_agent = chat_agent

                    # æ¨™è¨˜è™•ç†å®Œæˆ
                    st.session_state.video_processed = True

                    # é‡ç½®èŠå¤©æ­·å²
                    st.session_state.chat_history = []

                st.success("è¦–é »è™•ç†å®Œæˆï¼")
            except Exception as e:
                st.error(f"è™•ç†è¦–é »æ™‚å‡ºéŒ¯: {str(e)}")

        if st.session_state.video_processed:
            # é¡¯ç¤ºè¦–é »ä¿¡æ¯
            st.subheader("è¦–é »ä¿¡æ¯")
            st.write(f"æ¨™é¡Œ: {st.session_state.video_info['title']}")
            st.write(f"ä½œè€…: {st.session_state.video_info['author']}")
            st.write(f"æ™‚é•·: {format_timestamp(st.session_state.video_info['length'])}")
            st.write(f"è§€çœ‹æ•¸: {st.session_state.video_info['views']}")

    # ä¸»é é¢ - åœ¨è¦–é »è™•ç†å®Œæˆå¾Œé¡¯ç¤º
    if st.session_state.video_processed:
        # å‰µå»ºä¸‰å€‹æ¨™ç±¤
        tab1, tab2, tab3 = st.tabs(["è¦–é »æ‘˜è¦", "å­—å¹•èˆ‡ç¿»è­¯", "AI åŠ©æ‰‹å°è©±"])

        # æ¨™ç±¤ 1: è¦–é »æ‘˜è¦
        with tab1:
            st.header("è¦–é »æ‘˜è¦")
            st.write(st.session_state.summary)

        # æ¨™ç±¤ 2: å­—å¹•èˆ‡ç¿»è­¯
        with tab2:
            st.header("å­—å¹•èˆ‡ç¿»è­¯")

            # å‰µå»º DataFrame é¡¯ç¤ºå­—å¹•å’Œç¿»è­¯
            import pandas as pd

            subtitles_data = []
            for segment in st.session_state.translated_segments:
                subtitles_data.append({
                    "æ™‚é–“": f"{segment['start_formatted']} - {segment['end_formatted']}",
                    "åŸæ–‡": segment["text"],
                    "ç¿»è­¯": segment["translation"]
                })

            df = pd.DataFrame(subtitles_data)
            st.dataframe(df, use_container_width=True)

        # æ¨™ç±¤ 3: AI åŠ©æ‰‹å°è©±
        with tab3:
            st.header("èˆ‡è¦–é »å…§å®¹å°è©±")

            # é¡¯ç¤ºå°è©±æ­·å²
            for message in st.session_state.chat_history:
                if message["role"] == "user":
                    st.chat_message("user").write(message["content"])
                else:
                    st.chat_message("assistant").write(message["content"])

            # ç”¨æˆ¶è¼¸å…¥
            user_query = st.chat_input("å•æˆ‘é—œæ–¼è¦–é »çš„å•é¡Œ...")

            if user_query:
                # æ·»åŠ ç”¨æˆ¶æ¶ˆæ¯åˆ°æ­·å²
                st.session_state.chat_history.append({"role": "user", "content": user_query})
                st.chat_message("user").write(user_query)

                # ç²å– AI å›æ‡‰
                with st.spinner("æ€è€ƒä¸­..."):
                    response = chat_with_video(
                        st.session_state.chat_agent,
                        user_query,
                        st.session_state.thread_id,
                        st.session_state.video_id
                    )

                # æ·»åŠ  AI å›æ‡‰åˆ°æ­·å²
                st.session_state.chat_history.append({"role": "assistant", "content": response})
                st.chat_message("assistant").write(response)
    else:
        # æœªè™•ç†è¦–é »æ™‚é¡¯ç¤ºèªªæ˜
        st.info("è«‹åœ¨å·¦å´è¼¸å…¥ YouTube è¦–é » URL ä¸¦é»æ“Š 'è™•ç†è¦–é »' æŒ‰éˆ•é–‹å§‹")
        st.write("""
        ### ä½¿ç”¨èªªæ˜

        1. åœ¨å·¦å´è¼¸å…¥ä¸€å€‹ YouTube è¦–é »çš„ URL
        2. é»æ“Š 'è™•ç†è¦–é »' æŒ‰éˆ•é–‹å§‹åˆ†æ
        3. ç³»çµ±å°‡æå–è¦–é »å­—å¹•ã€ç”Ÿæˆæ‘˜è¦ã€ç¿»è­¯å…§å®¹ä¸¦å»ºç«‹å°è©±åŠ©æ‰‹
        4. åœ¨ 'è¦–é »æ‘˜è¦' æ¨™ç±¤æŸ¥çœ‹å…§å®¹æ¦‚è¿°
        5. åœ¨ 'å­—å¹•èˆ‡ç¿»è­¯' æ¨™ç±¤æŸ¥çœ‹åŸæ–‡èˆ‡ç¿»è­¯å°ç…§
        6. åœ¨ 'AI åŠ©æ‰‹å°è©±' æ¨™ç±¤èˆ‡åŸºæ–¼è¦–é »å…§å®¹çš„ AI é€²è¡Œå°è©±
        """)

if __name__ == "__main__":
    main()
```

## 7. æ•¸æ“šå­˜å„²å’Œç·©å­˜å¯¦ç¾

### ä½¿ç”¨ FAISS å­˜å„²å‘é‡æ•¸æ“š

```python
def create_persistent_vector_store(video_id: str, documents: list, embeddings):
    """å‰µå»ºæŒä¹…åŒ–å‘é‡å­˜å„²"""
    # ä½¿ç”¨ FAISS å‰µå»ºå‘é‡å­˜å„²
    vector_store = FAISS.from_documents(documents, embeddings)

    # ä¿å­˜å‘é‡å­˜å„²
    vector_store.save_local(f"vector_stores/{video_id}")

    return vector_store

def load_vector_store(video_id: str, embeddings):
    """åŠ è¼‰æŒä¹…åŒ–å‘é‡å­˜å„²"""
    try:
        # å˜—è©¦åŠ è¼‰ç¾æœ‰çš„å‘é‡å­˜å„²
        vector_store = FAISS.load_local(f"vector_stores/{video_id}", embeddings)
        return vector_store
    except:
        return None
```

### ä½¿ç”¨ LangGraph çš„ MemorySaver å¯¦ç¾å°è©±è¨˜æ†¶

```python
from langgraph.checkpoint.memory import MemorySaver

# å‰µå»ºè¨˜æ†¶é«”ä¿å­˜å™¨
memory = MemorySaver()

# åœ¨åœ–ç·¨è­¯æ™‚ä½¿ç”¨
graph = workflow.compile(checkpointer=memory)

# åœ¨èª¿ç”¨æ™‚æä¾› thread_id
config = {"configurable": {"thread_id": thread_id}}
result = graph.invoke(state, config=config)
```

## é …ç›®çµæ§‹

```
youtube_ai_assistant/
â”œâ”€â”€ app.py                   # Streamlit æ‡‰ç”¨ä¸»å…¥å£
â”œâ”€â”€ requirements.txt         # ä¾è³´é …
â”œâ”€â”€ .env                     # ç’°å¢ƒè®Šé‡
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ youtube_utils.py     # YouTube ç›¸é—œåŠŸèƒ½
â”‚   â”œâ”€â”€ text_processor.py    # æ–‡æœ¬è™•ç†åŠŸèƒ½
â”‚   â”œâ”€â”€ translator.py        # ç¿»è­¯åŠŸèƒ½
â”‚   â”œâ”€â”€ summarizer.py        # æ‘˜è¦ç”ŸæˆåŠŸèƒ½
â”‚   â””â”€â”€ chat_agent.py        # å°è©±ä»£ç†åŠŸèƒ½
â”œâ”€â”€ data/
â”‚   â””â”€â”€ vector_stores/       # å‘é‡å­˜å„²
â””â”€â”€ docs/
    â”œâ”€â”€ system_architecture.md
    â””â”€â”€ technical_implementation.md
```
